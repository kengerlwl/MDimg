# 有监督

有x，也有y。建立一个x->y的映射模型。

最常见的模型



# 无监督

只有x，无y。

一般是利用x自身的数据来做一些聚类啥的。

例如：k-means



# 半监督学习（Semi-supervised Learning）

在**有标签数据+无标签数据混合成的训练数据**中使用的机器学习算法。

一般假设，**无标签数据比有标签数据多，甚至多得多。**

## 需要的原因

- 有标记样本难以获取：需要专门的人员，特别的设备，额外的开销......
- 无标记的样本相对而言是很廉价的



## 用法

很多半监督学习算法中用的训练数据还有挺多要求的，一般默认的有：无标签数据一般是有标签数据中的某一个类别的（不要不属于的，也不要属于多个类别的）；有标签数据的标签应该都是对的；无标签数据一般是类别平衡的（即每一类的样本数差不多）；无标签数据的分布应该和有标签的相同或类似 等等。



简单介绍如下：

1.**简单自训练**（simple self-training）：用有标签数据训练一个分类器，然后用这个分类器对无标签数据进行分类，这样就会产生伪标签（pseudo label）或软标签（soft label），挑选你认为分类正确的无标签样本（此处应该有一个**挑选准则**），把选出来的无标签样本用来训练分类器。

2.**协同训练**（co-training）：其实也是 self-training 的一种，但其思想是好的。假设每个数据可以从不同的角度（view）进行分类，不同角度可以训练出不同的分类器，然后用这些从不同角度训练出来的分类器对无标签样本进行分类，再选出认为可信的无标签样本加入训练集中。由于这些分类器从不同角度训练出来的，可以形成一种互补，而提高分类精度；就如同从不同角度可以更好地理解事物一样。

3.**半监督字典学习**：其实也是 self-training 的一种，先是用有标签数据作为字典，对无标签数据进行分类，挑选出你认为分类正确的无标签样本，加入字典中（此时的字典就变成了半监督字典了）

4.**标签传播算法**（Label Propagation Algorithm）：是一种基于图的半监督算法，通过构造图结构（数据点为顶点，点之间的相似性为边）来寻找**训练数据**中有标签数据和无标签数据的关系。是的，只是训练数据中，这是一种直推式的半监督算法，即只对训练集中的无标签数据进行分类，这其实感觉很像一个有监督分类算法...，但其实并不是，因为其标签传播的过程，会流经无标签数据，即有些无标签数据的标签的信息，是从另一些无标签数据中流过来的，这就用到了无标签数据之间的联系





# 自监督 (self-supervised)

**从大规模的无监督数据中挖掘自身的监督信息**，通过这种构造的监督信息对网络进行训练，从而可以学习到对下游任务有价值的表征。（也就是说自监督学习的监督信息不是人工标注的，而是算法在大规模无监督数据中自动构造监督信息，来进行监督学习或训练。因此，大多数时候，我们称之为无监督预训练方法或无监督学习方法，严格上讲，他应该叫自监督学习）。

## 特点

- **从数据x，y上来说**，属于无监督学习，因为没有标签数据y
- **从训练过程来说**，属于有监督学习，因为自动构造了loss。



# 弱监督学习

 机器学习，深度学习在很多任务中获得很大的成功，尤其是在监督学习中，深度学习，机器学习取得了突破性的进展。 例如分类和回归的监督任务中，预测模型需要从大量有标注训练样本中学习，训练样本包含两部分：第一部分是对象的特征向量，第二部分是真值标签。在分类任务中，label表示训练样本的类别，在回归任务中，标签是一个与样本相对应的实数值。这些模型依赖强监督信息，例如深度学习模型依赖大量的标注数据，在实际生产中，数据的标注成本很高，获取大量的有标注样本难度大。 因此利用弱监督学习，利用大量无标注或者粗糙标注的样本来进行模型的学习，这样能够有效的利用数据，提升模型的性能
